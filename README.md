# Influence Maximization Lab

ä¸€ä¸ªå®Œæ•´çš„å½±å“åŠ›æœ€å¤§åŒ–å®éªŒæ¡†æ¶ï¼Œæ”¯æŒä»çº§è”æ•°æ®ä¸­å­¦ä¹ æ‰©æ•£å‚æ•°ï¼Œå¹¶åº”ç”¨äºå½±å“åŠ›æœ€å¤§åŒ–ç®—æ³•ã€‚

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-ee4c2c.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## ğŸ“‹ é¡¹ç›®æ¦‚è¿°

æœ¬é¡¹ç›®å®ç°äº†ä¸€ä¸ªå®Œæ•´çš„å½±å“åŠ›æœ€å¤§åŒ–ç ”ç©¶æ¡†æ¶ï¼Œä¸»è¦åŠŸèƒ½åŒ…æ‹¬ï¼š

1. **æ•°æ®ç”Ÿæˆæ¨¡å—**: ç”Ÿæˆåˆæˆç¤¾äº¤ç½‘ç»œï¼ˆER/BA/WSï¼‰å¹¶æ¨¡æ‹Ÿä¿¡æ¯çº§è”ä¼ æ’­
2. **çœŸå®æ•°æ®é›†æ”¯æŒ**: è‡ªåŠ¨ä¸‹è½½å’Œé¢„å¤„ç† Wiki-Voteã€Email-Enronã€Facebook ç­‰çœŸå®ç¤¾äº¤ç½‘ç»œ
3. **å‚æ•°å­¦ä¹ æ¨¡å—**: ä½¿ç”¨ PyTorch ä»çº§è”æ•°æ®ä¸­å­¦ä¹  IC æ¨¡å‹çš„è¾¹ä¼ æ’­æ¦‚ç‡
4. **é«˜çº§ç‰¹å¾å·¥ç¨‹**: ç»“æ„ç‰¹å¾ï¼ˆåº¦ä¸­å¿ƒæ€§ã€PageRankã€èšç±»ç³»æ•°ç­‰ï¼‰+ å›¾åµŒå…¥
5. **æ‰©æ•£ä»¿çœŸæ¨¡å—**: å®ç° IC å’Œ LT æ‰©æ•£æ¨¡å‹çš„è’™ç‰¹å¡æ´›ä»¿çœŸ
6. **å½±å“åŠ›æœ€å¤§åŒ–ç®—æ³•**: 10+ ç§ç®—æ³•ï¼ˆGreedyã€TIMã€IMMã€å¯å‘å¼æ–¹æ³•ç­‰ï¼‰
7. **ç½‘ç»œå¯è§†åŒ–**: ç½‘ç»œå›¾ã€çº§è”ä¼ æ’­åŠ¨ç”»ã€åº¦åˆ†å¸ƒç­‰å¯è§†åŒ–å·¥å…·
8. **äº¤äº’å¼æ•™ç¨‹**: Jupyter Notebook æ•™ç¨‹å’Œæ¡ˆä¾‹ç ”ç©¶
9. **å®éªŒå¯¹æ¯”**: å¯¹æ¯”çœŸå®å‚æ•°ä¸å­¦ä¹ å‚æ•°ä¸‹çš„å½±å“åŠ›æœ€å¤§åŒ–æ•ˆæœ
10. **å•å…ƒæµ‹è¯•**: å®Œæ•´çš„æµ‹è¯•å¥—ä»¶ç¡®ä¿ä»£ç è´¨é‡

## ğŸŒŸ ä¸»è¦ç‰¹æ€§

- âœ… **å®Œæ•´çš„å®éªŒæµç¨‹**: ä»ç½‘ç»œç”Ÿæˆåˆ°å‚æ•°å­¦ä¹ å†åˆ°å½±å“åŠ›æœ€å¤§åŒ–
- âœ… **GPU åŠ é€Ÿ**: PyTorch æ¨¡å‹æ”¯æŒ CUDA åŠ é€Ÿè®­ç»ƒ
- âœ… **10+ ç§ IM ç®—æ³•**:
  - ç²¾ç¡®ç®—æ³•ï¼šGreedyã€Lazy Greedy (CELF)
  - è¿‘ä¼¼ç®—æ³•ï¼šTIMã€TIM+ã€IMM
  - å¯å‘å¼æ–¹æ³•ï¼šDegreeã€PageRankã€Betweennessã€Closenessã€K-Shellã€Random
- âœ… **çœŸå®æ•°æ®é›†**: è‡ªåŠ¨ä¸‹è½½ Stanford SNAP æ•°æ®é›†ï¼ˆWiki-Voteã€Email-Enronã€Facebookã€Google+ï¼‰
- âœ… **é«˜çº§ç‰¹å¾**: Node2Vecã€DeepWalk + 14 ç§ç»“æ„ç‰¹å¾ï¼ˆåº¦ä¸­å¿ƒæ€§ã€PageRankã€èšç±»ç³»æ•°ç­‰ï¼‰
- âœ… **å¯å¤ç°**: ç»Ÿä¸€çš„éšæœºç§å­ç®¡ç†ç¡®ä¿å®éªŒå¯é‡å¤
- âœ… **ä¸°å¯Œå¯è§†åŒ–**:
  - è®­ç»ƒæ›²çº¿ã€å½±å“åŠ›å¯¹æ¯”ã€è¿è¡Œæ—¶é—´å¯¹æ¯”
  - ç½‘ç»œæ‹“æ‰‘å¯è§†åŒ–ã€åº¦åˆ†å¸ƒåˆ†æ
  - çº§è”ä¼ æ’­åŠ¨ç”»å’Œå¿«ç…§
- âœ… **äº¤äº’å¼æ•™ç¨‹**: Jupyter Notebook è¯¦ç»†æ•™ç¨‹
- âœ… **çµæ´»é…ç½®**: é€šè¿‡å‘½ä»¤è¡Œå‚æ•°æ§åˆ¶æ‰€æœ‰å®éªŒè®¾ç½®
- âœ… **æµ‹è¯•è¦†ç›–**: å•å…ƒæµ‹è¯•ç¡®ä¿ä»£ç è´¨é‡

## ğŸ“ é¡¹ç›®ç»“æ„

```
influence_maximization_lab/
â”œâ”€â”€ src/                          # æºä»£ç 
â”‚   â”œâ”€â”€ data/                     # æ•°æ®ç”Ÿæˆå’Œå¤„ç†
â”‚   â”‚   â”œâ”€â”€ network_generator.py  # ç½‘ç»œç”Ÿæˆï¼ˆER/BA/WSï¼‰
â”‚   â”‚   â”œâ”€â”€ cascade_generator.py  # çº§è”æ¨¡æ‹Ÿ
â”‚   â”‚   â”œâ”€â”€ data_loader.py        # æ•°æ®åˆ’åˆ†
â”‚   â”‚   â””â”€â”€ real_datasets.py      # çœŸå®æ•°æ®é›†ä¸‹è½½å™¨ ğŸ†•
â”‚   â”œâ”€â”€ models/                   # æœºå™¨å­¦ä¹ æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ embeddings.py         # Node2Vec/DeepWalk
â”‚   â”‚   â”œâ”€â”€ param_learner.py      # PyTorch å‚æ•°å­¦ä¹ æ¨¡å‹
â”‚   â”‚   â””â”€â”€ advanced_features.py  # é«˜çº§ç»“æ„ç‰¹å¾ ğŸ†•
â”‚   â”œâ”€â”€ diffusion/                # æ‰©æ•£æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ ic_model.py           # IC æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ lt_model.py           # LT æ¨¡å‹
â”‚   â”‚   â””â”€â”€ simulator.py          # ç»Ÿä¸€ä»¿çœŸæ¥å£
â”‚   â”œâ”€â”€ influence_max/            # å½±å“åŠ›æœ€å¤§åŒ–ç®—æ³•
â”‚   â”‚   â”œâ”€â”€ greedy.py             # è´ªå¿ƒç®—æ³• (Greedy, Lazy Greedy)
â”‚   â”‚   â”œâ”€â”€ tim.py                # TIM/TIM+ ç®—æ³•
â”‚   â”‚   â”œâ”€â”€ imm.py                # IMM ç®—æ³• ğŸ†•
â”‚   â”‚   â””â”€â”€ heuristics.py         # å¯å‘å¼ç®—æ³• ğŸ†•
â”‚   â””â”€â”€ utils/                    # å·¥å…·å‡½æ•°
â”‚       â”œâ”€â”€ metrics.py            # è¯„ä¼°æŒ‡æ ‡
â”‚       â”œâ”€â”€ visualization.py      # åŸºç¡€å¯è§†åŒ–
â”‚       â”œâ”€â”€ network_viz.py        # ç½‘ç»œå¯è§†åŒ– ğŸ†•
â”‚       â””â”€â”€ io_utils.py           # æ–‡ä»¶è¯»å†™
â”œâ”€â”€ experiments/                  # å®éªŒè„šæœ¬
â”‚   â”œâ”€â”€ train_params.py           # è®­ç»ƒæ‰©æ•£å‚æ•°
â”‚   â”œâ”€â”€ run_influence_max.py      # è¿è¡Œå½±å“åŠ›æœ€å¤§åŒ–
â”‚   â”œâ”€â”€ compare_methods.py        # ç»¼åˆå¯¹æ¯”å®éªŒ
â”‚   â””â”€â”€ run_on_real_data.py       # çœŸå®æ•°æ®é›†å®éªŒ ğŸ†•
â”œâ”€â”€ tutorials/                    # Jupyter æ•™ç¨‹ ğŸ†•
â”‚   â””â”€â”€ 01_getting_started.ipynb  # å…¥é—¨æ•™ç¨‹
â”œâ”€â”€ tests/                        # å•å…ƒæµ‹è¯• ğŸ†•
â”‚   â””â”€â”€ test_data.py              # æ•°æ®æ¨¡å—æµ‹è¯•
â”œâ”€â”€ configs/                      # é…ç½®æ–‡ä»¶ ğŸ†•
â”‚   â””â”€â”€ example_config.yaml       # ç¤ºä¾‹é…ç½®
â”œâ”€â”€ data/                         # æ•°æ®ç›®å½•ï¼ˆç”Ÿæˆï¼‰
â”œâ”€â”€ outputs/                      # è¾“å‡ºç›®å½•ï¼ˆç”Ÿæˆï¼‰
â”œâ”€â”€ requirements.txt              # ä¾èµ–åˆ—è¡¨
â”œâ”€â”€ setup.py                      # å®‰è£…è„šæœ¬
â”œâ”€â”€ quickstart.sh/bat             # å¿«é€Ÿå¼€å§‹è„šæœ¬
â””â”€â”€ README.md                     # æœ¬æ–‡ä»¶
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒé…ç½®

#### ç³»ç»Ÿè¦æ±‚
- Python 3.8+
- CUDA 11.0+ (å¯é€‰ï¼Œç”¨äº GPU åŠ é€Ÿ)

#### å®‰è£…ä¾èµ–

```bash
# å…‹éš†æˆ–è¿›å…¥é¡¹ç›®ç›®å½•
cd influence_maximization_lab

# å®‰è£…åŸºç¡€ä¾èµ–
pip install -r requirements.txt

# ï¼ˆå¯é€‰ï¼‰å®‰è£… PyTorch with CUDA æ”¯æŒ
# è®¿é—® https://pytorch.org/ è·å–é€‚åˆæ‚¨ç³»ç»Ÿçš„å®‰è£…å‘½ä»¤
# ä¾‹å¦‚ (CUDA 11.8):
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
```

### 2. å¿«é€Ÿè¿è¡Œç¤ºä¾‹

#### ç¤ºä¾‹ 1: è®­ç»ƒæ‰©æ•£å‚æ•°

ä»åˆæˆç½‘ç»œç”Ÿæˆçº§è”æ•°æ®å¹¶è®­ç»ƒå‚æ•°å­¦ä¹ æ¨¡å‹ï¼š

> æ²¡æœ‰å¯ç”¨ GPU æ—¶ï¼Œå°† `--device` è®¾ä¸º `cpu` å³å¯ï¼Œå…¶ä½™å‚æ•°ä¿æŒä¸å˜ã€‚

```bash
python experiments/train_params.py \
    --network-type ba \
    --num-nodes 500 \
    --ba-m 3 \
    --num-cascades 1000 \
    --embedding-method node2vec \
    --epochs 100 \
    --device cuda \
    --seed 42 \
    --output-dir outputs/trained_models
```

CPU è¿è¡Œç¤ºä¾‹ï¼š

```bash
python experiments/train_params.py \
    --network-type ba \
    --num-nodes 500 \
    --ba-m 3 \
    --num-cascades 1000 \
    --embedding-method node2vec \
    --epochs 100 \
    --device cpu \
    --seed 42 \
    --output-dir outputs/trained_models_cpu
```

**è¾“å‡ºæ–‡ä»¶**:
- `outputs/trained_models/param_learner.pth` - è®­ç»ƒå¥½çš„æ¨¡å‹
- `outputs/trained_models/embeddings.txt` - èŠ‚ç‚¹åµŒå…¥
- `outputs/trained_models/network.edgelist` - ç”Ÿæˆçš„ç½‘ç»œ
- `outputs/trained_models/training_history.png` - è®­ç»ƒæ›²çº¿
- `outputs/trained_models/training_results.json` - å®Œæ•´å®éªŒç»“æœ

#### ç¤ºä¾‹ 2: è¿è¡Œå½±å“åŠ›æœ€å¤§åŒ–

ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œå½±å“åŠ›æœ€å¤§åŒ–ï¼š

```bash
python experiments/run_influence_max.py \
    --network-path outputs/trained_models/network.edgelist \
    --model-path outputs/trained_models/param_learner.pth \
    --embeddings-path outputs/trained_models/embeddings.txt \
    --algorithm lazy_greedy \
    --k 10 \
    --num-simulations 1000 \
    --compare-params \
    --num-runs 5 \
    --device cuda \
    --seed 42 \
    --output-dir outputs/im_results
```

**è¾“å‡ºæ–‡ä»¶**:
- `outputs/im_results/im_results.json` - å®Œæ•´ç»“æœ
- `outputs/im_results/influence_comparison.png` - å½±å“åŠ›å¯¹æ¯”å›¾
- `outputs/im_results/runtime_comparison.png` - è¿è¡Œæ—¶é—´å¯¹æ¯”å›¾

#### ç¤ºä¾‹ 3: ç»¼åˆå¯¹æ¯”å®éªŒ

å¯¹æ¯”å¤šç§ç®—æ³•å’Œå‚æ•°è®¾ç½®ï¼š

```bash
python experiments/compare_methods.py \
    --network-type ba \
    --num-nodes 500 \
    --k-values 10 20 30 \
    --algorithms lazy_greedy tim tim_plus \
    --train-params \
    --num-runs 3 \
    --device cuda \
    --output-dir outputs/comparison
```

**è¾“å‡ºæ–‡ä»¶**:
- `outputs/comparison/comparison_results.csv` - CSV æ ¼å¼ç»“æœè¡¨
- `outputs/comparison/comparison_results.json` - JSON æ ¼å¼å®Œæ•´ç»“æœ
- `outputs/comparison/influence_comparison_k*.png` - å„ k å€¼ä¸‹çš„å½±å“åŠ›å¯¹æ¯”
- `outputs/comparison/runtime_comparison_k*.png` - è¿è¡Œæ—¶é—´å¯¹æ¯”

#### ç¤ºä¾‹ 4: çœŸå®æ•°æ®é›†å®éªŒ ğŸ†•

åœ¨çœŸå®ç¤¾äº¤ç½‘ç»œæ•°æ®é›†ä¸Šè¿è¡Œå½±å“åŠ›æœ€å¤§åŒ–ï¼š

```bash
python experiments/run_on_real_data.py \
    --dataset wiki-vote \
    --algorithms degree pagerank lazy_greedy tim \
    --k 50 \
    --num-simulations 1000 \
    --prob-method wc \
    --output-dir outputs/real_datasets
```

æ”¯æŒçš„æ•°æ®é›†:
- `wiki-vote`: Wikipedia æŠ•ç¥¨ç½‘ç»œ (7K èŠ‚ç‚¹)
- `email-enron`: Enron é‚®ä»¶ç½‘ç»œ (37K èŠ‚ç‚¹)
- `facebook`: Facebook ç¤¾äº¤åœˆ (4K èŠ‚ç‚¹)
- `gplus`: Google+ ç¤¾äº¤åœˆ (108K èŠ‚ç‚¹)

**è¾“å‡ºæ–‡ä»¶**:
- `outputs/real_datasets/wiki-vote_results.json` - å®Œæ•´ç»“æœ
- `outputs/real_datasets/wiki-vote_preprocessed.edgelist` - é¢„å¤„ç†åçš„ç½‘ç»œ
- `outputs/real_datasets/wiki-vote_influence_comparison.png` - å½±å“åŠ›å¯¹æ¯”

#### ç¤ºä¾‹ 5: äº¤äº’å¼æ•™ç¨‹ ğŸ†•

è¿è¡Œ Jupyter Notebook æ•™ç¨‹ï¼š

```bash
# å¯åŠ¨ Jupyter
jupyter notebook tutorials/01_getting_started.ipynb
```

æ•™ç¨‹å†…å®¹åŒ…æ‹¬ï¼š
- ç½‘ç»œç”Ÿæˆå’Œå¯è§†åŒ–
- çº§è”æ¨¡æ‹Ÿ
- å‚æ•°å­¦ä¹ 
- å½±å“åŠ›æœ€å¤§åŒ–ç®—æ³•å¯¹æ¯”
- å¯è§†åŒ–åˆ†æ

## ğŸ“– è¯¦ç»†ä½¿ç”¨è¯´æ˜

### æ•°æ®æ ¼å¼

#### ç½‘ç»œè¾¹åˆ—è¡¨æ ¼å¼ (Edge List)
```
# æ ¼å¼: source target [probability]
0 1 0.05
0 2 0.08
1 3 0.03
```

#### çº§è”æ•°æ®æ ¼å¼ (Cascade Log)
```
# æ ¼å¼: cascade_id source target [timestamp]
0 1 2 100
0 2 5 120
0 1 3 130
1 4 8 100
```

### æ ¸å¿ƒæ¨¡å—ä½¿ç”¨

#### 1. ç”Ÿæˆç½‘ç»œ

```python
from src.data import NetworkGenerator

# åˆ›å»ºç”Ÿæˆå™¨
gen = NetworkGenerator(seed=42)

# ç”Ÿæˆ BA ç½‘ç»œ
G = gen.generate_ba(n=500, m=3)

# åˆ†é… IC ä¼ æ’­æ¦‚ç‡
G = gen.assign_ic_probabilities(G, prob_range=(0.01, 0.1))

# æˆ–åŠ è½½å·²æœ‰ç½‘ç»œ
G = gen.load_from_edgelist('network.txt')
```

#### 2. ç”Ÿæˆçº§è”æ•°æ®

```python
from src.data import CascadeGenerator

# åˆ›å»ºçº§è”ç”Ÿæˆå™¨
cascade_gen = CascadeGenerator(G, seed=42)

# ç”Ÿæˆçº§è”
cascades = cascade_gen.generate_cascades(
    model='ic',
    num_cascades=1000,
    initial_size_range=(1, 5)
)

# è½¬æ¢ä¸ºè®­ç»ƒæ•°æ®
edges, labels = cascade_gen.cascades_to_training_data(cascades)
```

#### 3. è®­ç»ƒå‚æ•°å­¦ä¹ æ¨¡å‹

```python
from src.models import GraphEmbedding, ParameterLearner
import numpy as np

# ç”ŸæˆåµŒå…¥
embedding_gen = GraphEmbedding(G, embedding_dim=128, seed=42)
embeddings = embedding_gen.train_node2vec(num_walks=10, walk_length=80)

# å‡†å¤‡ç‰¹å¾
features = np.array([embedding_gen.get_edge_features(e) for e in edges])
labels = np.array(labels)

# è®­ç»ƒæ¨¡å‹
learner = ParameterLearner(
    input_dim=features.shape[1],
    hidden_dims=[256, 128, 64],
    device='cuda'
)

history = learner.fit(
    features, labels,
    epochs=100,
    batch_size=256
)
```

#### 4. è¿è¡Œå½±å“åŠ›æœ€å¤§åŒ–

```python
from src.diffusion import DiffusionSimulator
from src.influence_max import LazyGreedyIM, TIM

# åˆ›å»ºæ¨¡æ‹Ÿå™¨
sim = DiffusionSimulator(G, model='ic', seed=42)

# æ–¹æ³• 1: Lazy Greedy
greedy = LazyGreedyIM(G, sim, seed=42)
seeds, gains, runtime = greedy.select_seeds(k=10, num_simulations=1000)

# æ–¹æ³• 2: TIM
tim = TIM(G, model='ic', seed=42)
seeds, influence, runtime = tim.select_seeds(k=10, epsilon=0.2)

# è¯„ä¼°å½±å“åŠ›
actual_influence = sim.estimate_influence(seeds, num_simulations=1000)
print(f"Selected seeds: {seeds}")
print(f"Expected influence: {actual_influence}")
```

## ğŸ”¬ å®éªŒå¤ç°

### å®Œæ•´å®éªŒæµç¨‹

```bash
# Step 1: è®­ç»ƒå‚æ•°ï¼ˆ~5-10 åˆ†é’Ÿï¼Œå–å†³äºç½‘ç»œè§„æ¨¡ï¼‰
python experiments/train_params.py \
    --network-type ba --num-nodes 1000 --ba-m 3 \
    --num-cascades 2000 \
    --embedding-dim 128 \
    --epochs 100 \
    --device cuda \
    --seed 42 \
    --output-dir outputs/exp1

# Step 2: å¯¹æ¯”å½±å“åŠ›æœ€å¤§åŒ–ï¼ˆ~10-20 åˆ†é’Ÿï¼‰
python experiments/run_influence_max.py \
    --network-path outputs/exp1/network.edgelist \
    --model-path outputs/exp1/param_learner.pth \
    --embeddings-path outputs/exp1/embeddings.txt \
    --algorithm lazy_greedy \
    --k 20 \
    --num-simulations 1000 \
    --compare-params \
    --num-runs 10 \
    --device cuda \
    --output-dir outputs/exp1/im_results

# Step 3: ç»¼åˆå¯¹æ¯”ï¼ˆ~30-60 åˆ†é’Ÿï¼‰
python experiments/compare_methods.py \
    --num-nodes 1000 \
    --k-values 10 20 30 40 50 \
    --algorithms lazy_greedy tim tim_plus \
    --train-params \
    --num-runs 5 \
    --device cuda \
    --output-dir outputs/exp1/comparison
```

### ä¸åŒç½‘ç»œç±»å‹å®éªŒ

```bash
# ER ç½‘ç»œ
python experiments/train_params.py --network-type er --num-nodes 500 --er-p 0.01

# WS å°ä¸–ç•Œç½‘ç»œ
python experiments/train_params.py --network-type ws --num-nodes 500 --ws-k 4 --ws-p 0.1

# BA æ— æ ‡åº¦ç½‘ç»œï¼ˆé»˜è®¤ï¼‰
python experiments/train_params.py --network-type ba --num-nodes 500 --ba-m 3
```

## ğŸ“Š è¯„ä¼°æŒ‡æ ‡

### å‚æ•°å­¦ä¹ æŒ‡æ ‡
- **AUC (Area Under ROC Curve)**: è¯„ä¼°æ¦‚ç‡é¢„æµ‹è´¨é‡
- **Accuracy**: äºŒåˆ†ç±»å‡†ç¡®ç‡ï¼ˆé˜ˆå€¼ 0.5ï¼‰
- **Training Loss**: BCE (Binary Cross Entropy) æŸå¤±

### å½±å“åŠ›æœ€å¤§åŒ–æŒ‡æ ‡
- **Expected Influence**: é€šè¿‡è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿä¼°è®¡çš„æœŸæœ›å½±å“èŠ‚ç‚¹æ•°
- **Runtime**: ç®—æ³•è¿è¡Œæ—¶é—´ï¼ˆç§’ï¼‰
- **Seed Set Overlap**: çœŸå®å‚æ•°ä¸å­¦ä¹ å‚æ•°é€‰å‡ºçš„ç§å­èŠ‚ç‚¹é‡å åº¦

## âš™ï¸ é«˜çº§é…ç½®

### å‘½ä»¤è¡Œå‚æ•°è¯¦è§£

#### train_params.py ä¸»è¦å‚æ•°

| å‚æ•°              | è¯´æ˜                | é»˜è®¤å€¼         |
| ----------------- | ------------------- | -------------- |
| `--network-type`  | ç½‘ç»œç±»å‹ (er/ba/ws) | ba             |
| `--num-nodes`     | èŠ‚ç‚¹æ•°              | 500            |
| `--num-cascades`  | çº§è”æ•°é‡            | 1000           |
| `--embedding-dim` | åµŒå…¥ç»´åº¦            | 128            |
| `--hidden-dims`   | MLP éšè—å±‚ç»´åº¦      | [256, 128, 64] |
| `--epochs`        | è®­ç»ƒè½®æ•°            | 100            |
| `--batch-size`    | æ‰¹æ¬¡å¤§å°            | 256            |
| `--learning-rate` | å­¦ä¹ ç‡              | 0.001          |
| `--device`        | è®¾å¤‡ (cuda/cpu)     | cuda           |
| `--seed`          | éšæœºç§å­            | 42             |

#### run_influence_max.py ä¸»è¦å‚æ•°

| å‚æ•°                | è¯´æ˜                  | é»˜è®¤å€¼      |
| ------------------- | --------------------- | ----------- |
| `--algorithm`       | IM ç®—æ³•               | lazy_greedy |
| `--k`               | ç§å­èŠ‚ç‚¹æ•°            | 10          |
| `--num-simulations` | MC æ¨¡æ‹Ÿæ¬¡æ•°           | 1000        |
| `--compare-params`  | æ˜¯å¦å¯¹æ¯”çœŸå®/å­¦ä¹ å‚æ•° | False       |
| `--num-runs`        | å®éªŒé‡å¤æ¬¡æ•°          | 5           |
| `--parallel`        | æ˜¯å¦å¹¶è¡Œæ¨¡æ‹Ÿ          | False       |

### æ€§èƒ½ä¼˜åŒ–å»ºè®®

1. **GPU åŠ é€Ÿ**: ä½¿ç”¨ `--device cuda` åŠ é€Ÿå‚æ•°å­¦ä¹ 
2. **å¹¶è¡Œæ¨¡æ‹Ÿ**: å¯¹äºå¤§è§„æ¨¡å®éªŒï¼Œä½¿ç”¨ `--parallel --num-workers 8`
3. **å‡å°‘æ¨¡æ‹Ÿæ¬¡æ•°**: åˆæ­¥æµ‹è¯•æ—¶ä½¿ç”¨è¾ƒå°‘çš„ MC æ¨¡æ‹Ÿ (å¦‚ 100-500)
4. **æ—©åœæœºåˆ¶**: å·²é›†æˆï¼Œè®­ç»ƒä¼šåœ¨éªŒè¯æŸå¤±ä¸å†ä¸‹é™æ—¶è‡ªåŠ¨åœæ­¢

## ğŸ“ˆ å®éªŒç»“æœç¤ºä¾‹

### è®­ç»ƒæ›²çº¿
è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šè‡ªåŠ¨ç”Ÿæˆ Loss å’Œ AUC æ›²çº¿ï¼š

![Training History](outputs/trained_models/training_history.png)

### å½±å“åŠ›å¯¹æ¯”
å¯¹æ¯”çœŸå®å‚æ•°ä¸å­¦ä¹ å‚æ•°ä¸‹çš„å½±å“åŠ›ï¼š

```
True Parameters:
  Mean Influence: 145.32 Â± 3.21
  Mean Runtime: 12.45s

Learned Parameters:
  Mean Influence: 142.18 Â± 3.56
  Mean Runtime: 12.38s
```

### ç®—æ³•æ€§èƒ½å¯¹æ¯”

| ç®—æ³•        | k=10 å½±å“åŠ› | k=20 å½±å“åŠ› | è¿è¡Œæ—¶é—´ |
| ----------- | ----------- | ----------- | -------- |
| Greedy      | 98.5        | 156.3       | 180s     |
| Lazy Greedy | 98.5        | 156.3       | 15s      |
| TIM         | 97.2        | 154.8       | 8s       |
| TIM+        | 97.8        | 155.4       | 6s       |

## ğŸ› ï¸ æ‰©å±•åŠŸèƒ½

### å¯¼å…¥å¤–éƒ¨æ•°æ®

```python
# å¯¼å…¥ç½‘ç»œ
from src.data import NetworkGenerator
gen = NetworkGenerator()
G = gen.load_from_edgelist('your_network.txt')

# å¯¼å…¥çº§è”
from src.data import load_cascades_from_file
cascades = load_cascades_from_file('your_cascades.txt')
```

### è‡ªå®šä¹‰æ‰©æ•£æ¨¡å‹

å¯ä»¥åœ¨ `src/diffusion/` ä¸­å®ç°è‡ªå®šä¹‰æ‰©æ•£æ¨¡å‹ï¼Œåªéœ€ç»§æ‰¿åŸºç±»å¹¶å®ç° `simulate_single` æ–¹æ³•ã€‚

### è‡ªå®šä¹‰ IM ç®—æ³•

å¯ä»¥åœ¨ `src/influence_max/` ä¸­å®ç°æ–°ç®—æ³•ï¼Œå‚è€ƒç°æœ‰çš„ `GreedyIM` æˆ– `TIM` ç±»ã€‚

## ğŸ› å¸¸è§é—®é¢˜

### Q1: CUDA out of memory
**A**: å‡å°‘ `--batch-size` æˆ–ä½¿ç”¨ `--device cpu`

### Q2: è®­ç»ƒé€Ÿåº¦æ…¢
**A**:
- ç¡®ä¿ä½¿ç”¨ GPU (`--device cuda`)
- å‡å°‘ `--num-cascades` æˆ– `--epochs`
- å‡å°ç½‘ç»œè§„æ¨¡ `--num-nodes`

### Q3: å½±å“åŠ›ä¼°è®¡ä¸ç¨³å®š
**A**: å¢åŠ  `--num-simulations` (å¦‚ 5000-10000)

### Q4: TIM ç®—æ³•è¿è¡Œå¤±è´¥
**A**: è°ƒæ•´ `--tim-epsilon` å‚æ•°ï¼Œè¾ƒå°çš„ epsilon ä¼šç”Ÿæˆæ›´å¤š RR sets

## ğŸ“š å‚è€ƒæ–‡çŒ®

1. **Independent Cascade Model**: Kempe, D., Kleinberg, J., & Tardos, Ã‰. (2003). Maximizing the spread of influence through a social network. KDD.

2. **TIM/TIM+**: Tang, Y., Xiao, X., & Shi, Y. (2014). Influence maximization: Near-optimal time complexity meets practical efficiency. SIGMOD.

3. **Node2Vec**: Grover, A., & Leskovec, J. (2016). node2vec: Scalable feature learning for networks. KDD.

4. **DeepWalk**: Perozzi, B., Al-Rfou, R., & Skiena, S. (2014). DeepWalk: Online learning of social representations. KDD.

## ğŸ“„ License

æœ¬é¡¹ç›®é‡‡ç”¨ MIT License å¼€æºåè®®ã€‚

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼

## ğŸ“§ è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼è”ç³»ï¼š
- æäº¤ GitHub Issue
- é‚®ä»¶è”ç³»ï¼ˆè¯·åœ¨æ­¤æ·»åŠ æ‚¨çš„é‚®ç®±ï¼‰

---

**Happy Experimenting! ğŸ‰**
