# Influence Maximization Lab

ä¸€ä¸ªå®Œæ•´çš„å½±å“åŠ›æœ€å¤§åŒ–å®éªŒæ¡†æ¶ï¼Œæ”¯æŒä»çº§è”æ•°æ®ä¸­å­¦ä¹ æ‰©æ•£å‚æ•°ï¼Œå¹¶åº”ç”¨äºå½±å“åŠ›æœ€å¤§åŒ–ç®—æ³•ã€‚

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-ee4c2c.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## ğŸ“‹ é¡¹ç›®æ¦‚è¿°

æœ¬é¡¹ç›®å®ç°äº†ä¸€ä¸ªå®Œæ•´çš„å½±å“åŠ›æœ€å¤§åŒ–ç ”ç©¶æ¡†æ¶ï¼Œä¸»è¦åŠŸèƒ½åŒ…æ‹¬ï¼š

1. **æ•°æ®ç”Ÿæˆæ¨¡å—**: ç”Ÿæˆåˆæˆç¤¾äº¤ç½‘ç»œï¼ˆER/BA/WSï¼‰å¹¶æ¨¡æ‹Ÿä¿¡æ¯çº§è”ä¼ æ’­
2. **å‚æ•°å­¦ä¹ æ¨¡å—**: ä½¿ç”¨ PyTorch ä»çº§è”æ•°æ®ä¸­å­¦ä¹  IC æ¨¡å‹çš„è¾¹ä¼ æ’­æ¦‚ç‡
3. **æ‰©æ•£ä»¿çœŸæ¨¡å—**: å®ç° IC å’Œ LT æ‰©æ•£æ¨¡å‹çš„è’™ç‰¹å¡æ´›ä»¿çœŸ
4. **å½±å“åŠ›æœ€å¤§åŒ–æ¨¡å—**: å®ç°ç»å…¸è´ªå¿ƒç®—æ³•å’Œé«˜æ•ˆçš„ TIM/TIM+ ç®—æ³•
5. **å®éªŒå¯¹æ¯”**: å¯¹æ¯”çœŸå®å‚æ•°ä¸å­¦ä¹ å‚æ•°ä¸‹çš„å½±å“åŠ›æœ€å¤§åŒ–æ•ˆæœ

## ğŸŒŸ ä¸»è¦ç‰¹æ€§

- âœ… **å®Œæ•´çš„å®éªŒæµç¨‹**: ä»ç½‘ç»œç”Ÿæˆåˆ°å‚æ•°å­¦ä¹ å†åˆ°å½±å“åŠ›æœ€å¤§åŒ–
- âœ… **GPU åŠ é€Ÿ**: PyTorch æ¨¡å‹æ”¯æŒ CUDA åŠ é€Ÿè®­ç»ƒ
- âœ… **å¤šç§ç®—æ³•**: æ”¯æŒ Greedyã€Lazy Greedyã€TIMã€TIM+ ç­‰ç®—æ³•
- âœ… **å›¾åµŒå…¥**: é›†æˆ Node2Vec å’Œ DeepWalk ç”¨äºç‰¹å¾æå–
- âœ… **å¯å¤ç°**: ç»Ÿä¸€çš„éšæœºç§å­ç®¡ç†ç¡®ä¿å®éªŒå¯é‡å¤
- âœ… **å¯è§†åŒ–**: è‡ªåŠ¨ç”Ÿæˆè®­ç»ƒæ›²çº¿ã€å½±å“åŠ›å¯¹æ¯”ç­‰å›¾è¡¨
- âœ… **çµæ´»é…ç½®**: é€šè¿‡å‘½ä»¤è¡Œå‚æ•°æ§åˆ¶æ‰€æœ‰å®éªŒè®¾ç½®

## ğŸ“ é¡¹ç›®ç»“æ„

```
influence_maximization_lab/
â”œâ”€â”€ src/                          # æºä»£ç 
â”‚   â”œâ”€â”€ data/                     # æ•°æ®ç”Ÿæˆå’Œå¤„ç†
â”‚   â”‚   â”œâ”€â”€ network_generator.py  # ç½‘ç»œç”Ÿæˆï¼ˆER/BA/WSï¼‰
â”‚   â”‚   â”œâ”€â”€ cascade_generator.py  # çº§è”æ¨¡æ‹Ÿ
â”‚   â”‚   â””â”€â”€ data_loader.py        # æ•°æ®åˆ’åˆ†
â”‚   â”œâ”€â”€ models/                   # æœºå™¨å­¦ä¹ æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ embeddings.py         # Node2Vec/DeepWalk
â”‚   â”‚   â””â”€â”€ param_learner.py      # PyTorch å‚æ•°å­¦ä¹ æ¨¡å‹
â”‚   â”œâ”€â”€ diffusion/                # æ‰©æ•£æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ ic_model.py           # IC æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ lt_model.py           # LT æ¨¡å‹
â”‚   â”‚   â””â”€â”€ simulator.py          # ç»Ÿä¸€ä»¿çœŸæ¥å£
â”‚   â”œâ”€â”€ influence_max/            # å½±å“åŠ›æœ€å¤§åŒ–ç®—æ³•
â”‚   â”‚   â”œâ”€â”€ greedy.py             # è´ªå¿ƒç®—æ³•
â”‚   â”‚   â””â”€â”€ tim.py                # TIM/TIM+ ç®—æ³•
â”‚   â””â”€â”€ utils/                    # å·¥å…·å‡½æ•°
â”‚       â”œâ”€â”€ metrics.py            # è¯„ä¼°æŒ‡æ ‡
â”‚       â”œâ”€â”€ visualization.py      # å¯è§†åŒ–
â”‚       â””â”€â”€ io_utils.py           # æ–‡ä»¶è¯»å†™
â”œâ”€â”€ experiments/                  # å®éªŒè„šæœ¬
â”‚   â”œâ”€â”€ train_params.py           # è®­ç»ƒæ‰©æ•£å‚æ•°
â”‚   â”œâ”€â”€ run_influence_max.py      # è¿è¡Œå½±å“åŠ›æœ€å¤§åŒ–
â”‚   â””â”€â”€ compare_methods.py        # ç»¼åˆå¯¹æ¯”å®éªŒ
â”œâ”€â”€ data/                         # æ•°æ®ç›®å½•ï¼ˆç”Ÿæˆï¼‰
â”œâ”€â”€ outputs/                      # è¾“å‡ºç›®å½•ï¼ˆç”Ÿæˆï¼‰
â”œâ”€â”€ requirements.txt              # ä¾èµ–åˆ—è¡¨
â””â”€â”€ README.md                     # æœ¬æ–‡ä»¶
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒé…ç½®

#### ç³»ç»Ÿè¦æ±‚
- Python 3.8+
- CUDA 11.0+ (å¯é€‰ï¼Œç”¨äº GPU åŠ é€Ÿ)

#### å®‰è£…ä¾èµ–

```bash
# å…‹éš†æˆ–è¿›å…¥é¡¹ç›®ç›®å½•
cd influence_maximization_lab

# å®‰è£…åŸºç¡€ä¾èµ–
pip install -r requirements.txt

# ï¼ˆå¯é€‰ï¼‰å®‰è£… PyTorch with CUDA æ”¯æŒ
# è®¿é—® https://pytorch.org/ è·å–é€‚åˆæ‚¨ç³»ç»Ÿçš„å®‰è£…å‘½ä»¤
# ä¾‹å¦‚ (CUDA 11.8):
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
```

### 2. å¿«é€Ÿè¿è¡Œç¤ºä¾‹

#### ç¤ºä¾‹ 1: è®­ç»ƒæ‰©æ•£å‚æ•°

ä»åˆæˆç½‘ç»œç”Ÿæˆçº§è”æ•°æ®å¹¶è®­ç»ƒå‚æ•°å­¦ä¹ æ¨¡å‹ï¼š

```bash
python experiments/train_params.py \
    --network-type ba \
    --num-nodes 500 \
    --ba-m 3 \
    --num-cascades 1000 \
    --embedding-method node2vec \
    --epochs 100 \
    --device cuda \
    --seed 42 \
    --output-dir outputs/trained_models
```

**è¾“å‡ºæ–‡ä»¶**:
- `outputs/trained_models/param_learner.pth` - è®­ç»ƒå¥½çš„æ¨¡å‹
- `outputs/trained_models/embeddings.txt` - èŠ‚ç‚¹åµŒå…¥
- `outputs/trained_models/network.edgelist` - ç”Ÿæˆçš„ç½‘ç»œ
- `outputs/trained_models/training_history.png` - è®­ç»ƒæ›²çº¿
- `outputs/trained_models/training_results.json` - å®Œæ•´å®éªŒç»“æœ

#### ç¤ºä¾‹ 2: è¿è¡Œå½±å“åŠ›æœ€å¤§åŒ–

ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œå½±å“åŠ›æœ€å¤§åŒ–ï¼š

```bash
python experiments/run_influence_max.py \
    --network-path outputs/trained_models/network.edgelist \
    --model-path outputs/trained_models/param_learner.pth \
    --embeddings-path outputs/trained_models/embeddings.txt \
    --algorithm lazy_greedy \
    --k 10 \
    --num-simulations 1000 \
    --compare-params \
    --num-runs 5 \
    --device cuda \
    --seed 42 \
    --output-dir outputs/im_results
```

**è¾“å‡ºæ–‡ä»¶**:
- `outputs/im_results/im_results.json` - å®Œæ•´ç»“æœ
- `outputs/im_results/influence_comparison.png` - å½±å“åŠ›å¯¹æ¯”å›¾
- `outputs/im_results/runtime_comparison.png` - è¿è¡Œæ—¶é—´å¯¹æ¯”å›¾

#### ç¤ºä¾‹ 3: ç»¼åˆå¯¹æ¯”å®éªŒ

å¯¹æ¯”å¤šç§ç®—æ³•å’Œå‚æ•°è®¾ç½®ï¼š

```bash
python experiments/compare_methods.py \
    --network-type ba \
    --num-nodes 500 \
    --k-values 10 20 30 \
    --algorithms lazy_greedy tim tim_plus \
    --train-params \
    --num-runs 3 \
    --device cuda \
    --output-dir outputs/comparison
```

**è¾“å‡ºæ–‡ä»¶**:
- `outputs/comparison/comparison_results.csv` - CSV æ ¼å¼ç»“æœè¡¨
- `outputs/comparison/comparison_results.json` - JSON æ ¼å¼å®Œæ•´ç»“æœ
- `outputs/comparison/influence_comparison_k*.png` - å„ k å€¼ä¸‹çš„å½±å“åŠ›å¯¹æ¯”
- `outputs/comparison/runtime_comparison_k*.png` - è¿è¡Œæ—¶é—´å¯¹æ¯”

## ğŸ“– è¯¦ç»†ä½¿ç”¨è¯´æ˜

### æ•°æ®æ ¼å¼

#### ç½‘ç»œè¾¹åˆ—è¡¨æ ¼å¼ (Edge List)
```
# æ ¼å¼: source target [probability]
0 1 0.05
0 2 0.08
1 3 0.03
```

#### çº§è”æ•°æ®æ ¼å¼ (Cascade Log)
```
# æ ¼å¼: cascade_id source target [timestamp]
0 1 2 100
0 2 5 120
0 1 3 130
1 4 8 100
```

### æ ¸å¿ƒæ¨¡å—ä½¿ç”¨

#### 1. ç”Ÿæˆç½‘ç»œ

```python
from src.data import NetworkGenerator

# åˆ›å»ºç”Ÿæˆå™¨
gen = NetworkGenerator(seed=42)

# ç”Ÿæˆ BA ç½‘ç»œ
G = gen.generate_ba(n=500, m=3)

# åˆ†é… IC ä¼ æ’­æ¦‚ç‡
G = gen.assign_ic_probabilities(G, prob_range=(0.01, 0.1))

# æˆ–åŠ è½½å·²æœ‰ç½‘ç»œ
G = gen.load_from_edgelist('network.txt')
```

#### 2. ç”Ÿæˆçº§è”æ•°æ®

```python
from src.data import CascadeGenerator

# åˆ›å»ºçº§è”ç”Ÿæˆå™¨
cascade_gen = CascadeGenerator(G, seed=42)

# ç”Ÿæˆçº§è”
cascades = cascade_gen.generate_cascades(
    model='ic',
    num_cascades=1000,
    initial_size_range=(1, 5)
)

# è½¬æ¢ä¸ºè®­ç»ƒæ•°æ®
edges, labels = cascade_gen.cascades_to_training_data(cascades)
```

#### 3. è®­ç»ƒå‚æ•°å­¦ä¹ æ¨¡å‹

```python
from src.models import GraphEmbedding, ParameterLearner
import numpy as np

# ç”ŸæˆåµŒå…¥
embedding_gen = GraphEmbedding(G, embedding_dim=128, seed=42)
embeddings = embedding_gen.train_node2vec(num_walks=10, walk_length=80)

# å‡†å¤‡ç‰¹å¾
features = np.array([embedding_gen.get_edge_features(e) for e in edges])
labels = np.array(labels)

# è®­ç»ƒæ¨¡å‹
learner = ParameterLearner(
    input_dim=features.shape[1],
    hidden_dims=[256, 128, 64],
    device='cuda'
)

history = learner.fit(
    features, labels,
    epochs=100,
    batch_size=256
)
```

#### 4. è¿è¡Œå½±å“åŠ›æœ€å¤§åŒ–

```python
from src.diffusion import DiffusionSimulator
from src.influence_max import LazyGreedyIM, TIM

# åˆ›å»ºæ¨¡æ‹Ÿå™¨
sim = DiffusionSimulator(G, model='ic', seed=42)

# æ–¹æ³• 1: Lazy Greedy
greedy = LazyGreedyIM(G, sim, seed=42)
seeds, gains, runtime = greedy.select_seeds(k=10, num_simulations=1000)

# æ–¹æ³• 2: TIM
tim = TIM(G, model='ic', seed=42)
seeds, influence, runtime = tim.select_seeds(k=10, epsilon=0.2)

# è¯„ä¼°å½±å“åŠ›
actual_influence = sim.estimate_influence(seeds, num_simulations=1000)
print(f"Selected seeds: {seeds}")
print(f"Expected influence: {actual_influence}")
```

## ğŸ”¬ å®éªŒå¤ç°

### å®Œæ•´å®éªŒæµç¨‹

```bash
# Step 1: è®­ç»ƒå‚æ•°ï¼ˆ~5-10 åˆ†é’Ÿï¼Œå–å†³äºç½‘ç»œè§„æ¨¡ï¼‰
python experiments/train_params.py \
    --network-type ba --num-nodes 1000 --ba-m 3 \
    --num-cascades 2000 \
    --embedding-dim 128 \
    --epochs 100 \
    --device cuda \
    --seed 42 \
    --output-dir outputs/exp1

# Step 2: å¯¹æ¯”å½±å“åŠ›æœ€å¤§åŒ–ï¼ˆ~10-20 åˆ†é’Ÿï¼‰
python experiments/run_influence_max.py \
    --network-path outputs/exp1/network.edgelist \
    --model-path outputs/exp1/param_learner.pth \
    --embeddings-path outputs/exp1/embeddings.txt \
    --algorithm lazy_greedy \
    --k 20 \
    --num-simulations 1000 \
    --compare-params \
    --num-runs 10 \
    --device cuda \
    --output-dir outputs/exp1/im_results

# Step 3: ç»¼åˆå¯¹æ¯”ï¼ˆ~30-60 åˆ†é’Ÿï¼‰
python experiments/compare_methods.py \
    --num-nodes 1000 \
    --k-values 10 20 30 40 50 \
    --algorithms lazy_greedy tim tim_plus \
    --train-params \
    --num-runs 5 \
    --device cuda \
    --output-dir outputs/exp1/comparison
```

### ä¸åŒç½‘ç»œç±»å‹å®éªŒ

```bash
# ER ç½‘ç»œ
python experiments/train_params.py --network-type er --num-nodes 500 --er-p 0.01

# WS å°ä¸–ç•Œç½‘ç»œ
python experiments/train_params.py --network-type ws --num-nodes 500 --ws-k 4 --ws-p 0.1

# BA æ— æ ‡åº¦ç½‘ç»œï¼ˆé»˜è®¤ï¼‰
python experiments/train_params.py --network-type ba --num-nodes 500 --ba-m 3
```

## ğŸ“Š è¯„ä¼°æŒ‡æ ‡

### å‚æ•°å­¦ä¹ æŒ‡æ ‡
- **AUC (Area Under ROC Curve)**: è¯„ä¼°æ¦‚ç‡é¢„æµ‹è´¨é‡
- **Accuracy**: äºŒåˆ†ç±»å‡†ç¡®ç‡ï¼ˆé˜ˆå€¼ 0.5ï¼‰
- **Training Loss**: BCE (Binary Cross Entropy) æŸå¤±

### å½±å“åŠ›æœ€å¤§åŒ–æŒ‡æ ‡
- **Expected Influence**: é€šè¿‡è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿä¼°è®¡çš„æœŸæœ›å½±å“èŠ‚ç‚¹æ•°
- **Runtime**: ç®—æ³•è¿è¡Œæ—¶é—´ï¼ˆç§’ï¼‰
- **Seed Set Overlap**: çœŸå®å‚æ•°ä¸å­¦ä¹ å‚æ•°é€‰å‡ºçš„ç§å­èŠ‚ç‚¹é‡å åº¦

## âš™ï¸ é«˜çº§é…ç½®

### å‘½ä»¤è¡Œå‚æ•°è¯¦è§£

#### train_params.py ä¸»è¦å‚æ•°

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ |
|------|------|--------|
| `--network-type` | ç½‘ç»œç±»å‹ (er/ba/ws) | ba |
| `--num-nodes` | èŠ‚ç‚¹æ•° | 500 |
| `--num-cascades` | çº§è”æ•°é‡ | 1000 |
| `--embedding-dim` | åµŒå…¥ç»´åº¦ | 128 |
| `--hidden-dims` | MLP éšè—å±‚ç»´åº¦ | [256, 128, 64] |
| `--epochs` | è®­ç»ƒè½®æ•° | 100 |
| `--batch-size` | æ‰¹æ¬¡å¤§å° | 256 |
| `--learning-rate` | å­¦ä¹ ç‡ | 0.001 |
| `--device` | è®¾å¤‡ (cuda/cpu) | cuda |
| `--seed` | éšæœºç§å­ | 42 |

#### run_influence_max.py ä¸»è¦å‚æ•°

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ |
|------|------|--------|
| `--algorithm` | IM ç®—æ³• | lazy_greedy |
| `--k` | ç§å­èŠ‚ç‚¹æ•° | 10 |
| `--num-simulations` | MC æ¨¡æ‹Ÿæ¬¡æ•° | 1000 |
| `--compare-params` | æ˜¯å¦å¯¹æ¯”çœŸå®/å­¦ä¹ å‚æ•° | False |
| `--num-runs` | å®éªŒé‡å¤æ¬¡æ•° | 5 |
| `--parallel` | æ˜¯å¦å¹¶è¡Œæ¨¡æ‹Ÿ | False |

### æ€§èƒ½ä¼˜åŒ–å»ºè®®

1. **GPU åŠ é€Ÿ**: ä½¿ç”¨ `--device cuda` åŠ é€Ÿå‚æ•°å­¦ä¹ 
2. **å¹¶è¡Œæ¨¡æ‹Ÿ**: å¯¹äºå¤§è§„æ¨¡å®éªŒï¼Œä½¿ç”¨ `--parallel --num-workers 8`
3. **å‡å°‘æ¨¡æ‹Ÿæ¬¡æ•°**: åˆæ­¥æµ‹è¯•æ—¶ä½¿ç”¨è¾ƒå°‘çš„ MC æ¨¡æ‹Ÿ (å¦‚ 100-500)
4. **æ—©åœæœºåˆ¶**: å·²é›†æˆï¼Œè®­ç»ƒä¼šåœ¨éªŒè¯æŸå¤±ä¸å†ä¸‹é™æ—¶è‡ªåŠ¨åœæ­¢

## ğŸ“ˆ å®éªŒç»“æœç¤ºä¾‹

### è®­ç»ƒæ›²çº¿
è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šè‡ªåŠ¨ç”Ÿæˆ Loss å’Œ AUC æ›²çº¿ï¼š

![Training History](outputs/trained_models/training_history.png)

### å½±å“åŠ›å¯¹æ¯”
å¯¹æ¯”çœŸå®å‚æ•°ä¸å­¦ä¹ å‚æ•°ä¸‹çš„å½±å“åŠ›ï¼š

```
True Parameters:
  Mean Influence: 145.32 Â± 3.21
  Mean Runtime: 12.45s

Learned Parameters:
  Mean Influence: 142.18 Â± 3.56
  Mean Runtime: 12.38s
```

### ç®—æ³•æ€§èƒ½å¯¹æ¯”

| ç®—æ³• | k=10 å½±å“åŠ› | k=20 å½±å“åŠ› | è¿è¡Œæ—¶é—´ |
|------|------------|------------|---------|
| Greedy | 98.5 | 156.3 | 180s |
| Lazy Greedy | 98.5 | 156.3 | 15s |
| TIM | 97.2 | 154.8 | 8s |
| TIM+ | 97.8 | 155.4 | 6s |

## ğŸ› ï¸ æ‰©å±•åŠŸèƒ½

### å¯¼å…¥å¤–éƒ¨æ•°æ®

```python
# å¯¼å…¥ç½‘ç»œ
from src.data import NetworkGenerator
gen = NetworkGenerator()
G = gen.load_from_edgelist('your_network.txt')

# å¯¼å…¥çº§è”
from src.data import load_cascades_from_file
cascades = load_cascades_from_file('your_cascades.txt')
```

### è‡ªå®šä¹‰æ‰©æ•£æ¨¡å‹

å¯ä»¥åœ¨ `src/diffusion/` ä¸­å®ç°è‡ªå®šä¹‰æ‰©æ•£æ¨¡å‹ï¼Œåªéœ€ç»§æ‰¿åŸºç±»å¹¶å®ç° `simulate_single` æ–¹æ³•ã€‚

### è‡ªå®šä¹‰ IM ç®—æ³•

å¯ä»¥åœ¨ `src/influence_max/` ä¸­å®ç°æ–°ç®—æ³•ï¼Œå‚è€ƒç°æœ‰çš„ `GreedyIM` æˆ– `TIM` ç±»ã€‚

## ğŸ› å¸¸è§é—®é¢˜

### Q1: CUDA out of memory
**A**: å‡å°‘ `--batch-size` æˆ–ä½¿ç”¨ `--device cpu`

### Q2: è®­ç»ƒé€Ÿåº¦æ…¢
**A**:
- ç¡®ä¿ä½¿ç”¨ GPU (`--device cuda`)
- å‡å°‘ `--num-cascades` æˆ– `--epochs`
- å‡å°ç½‘ç»œè§„æ¨¡ `--num-nodes`

### Q3: å½±å“åŠ›ä¼°è®¡ä¸ç¨³å®š
**A**: å¢åŠ  `--num-simulations` (å¦‚ 5000-10000)

### Q4: TIM ç®—æ³•è¿è¡Œå¤±è´¥
**A**: è°ƒæ•´ `--tim-epsilon` å‚æ•°ï¼Œè¾ƒå°çš„ epsilon ä¼šç”Ÿæˆæ›´å¤š RR sets

## ğŸ“š å‚è€ƒæ–‡çŒ®

1. **Independent Cascade Model**: Kempe, D., Kleinberg, J., & Tardos, Ã‰. (2003). Maximizing the spread of influence through a social network. KDD.

2. **TIM/TIM+**: Tang, Y., Xiao, X., & Shi, Y. (2014). Influence maximization: Near-optimal time complexity meets practical efficiency. SIGMOD.

3. **Node2Vec**: Grover, A., & Leskovec, J. (2016). node2vec: Scalable feature learning for networks. KDD.

4. **DeepWalk**: Perozzi, B., Al-Rfou, R., & Skiena, S. (2014). DeepWalk: Online learning of social representations. KDD.

## ğŸ“„ License

æœ¬é¡¹ç›®é‡‡ç”¨ MIT License å¼€æºåè®®ã€‚

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼

## ğŸ“§ è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼è”ç³»ï¼š
- æäº¤ GitHub Issue
- é‚®ä»¶è”ç³»ï¼ˆè¯·åœ¨æ­¤æ·»åŠ æ‚¨çš„é‚®ç®±ï¼‰

---

**Happy Experimenting! ğŸ‰**
