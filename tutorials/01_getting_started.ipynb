{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 影响力最大化实验教程\n",
    "\n",
    "本教程将引导您完成整个影响力最大化实验流程，从网络生成到参数学习再到影响力最大化。\n",
    "\n",
    "## 目录\n",
    "1. 环境设置\n",
    "2. 生成网络和级联数据\n",
    "3. 训练参数学习模型\n",
    "4. 运行影响力最大化算法\n",
    "5. 对比分析\n",
    "6. 可视化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 环境设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# 添加 src 到路径\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from src.data import NetworkGenerator, CascadeGenerator, DataSplitter\n",
    "from src.models import GraphEmbedding, ParameterLearner\n",
    "from src.diffusion import DiffusionSimulator\n",
    "from src.influence_max import LazyGreedyIM, TIM, IMM\n",
    "from src.influence_max.heuristics import DegreeHeuristic, PageRankHeuristic\n",
    "from src.utils import plot_training_history, plot_influence_comparison\n",
    "from src.utils.network_viz import NetworkVisualizer, CascadeAnimator\n",
    "\n",
    "# 设置样式\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "# 设置随机种子\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "print(\"✓ 环境设置完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 生成网络和级联数据\n",
    "\n",
    "我们首先生成一个 BA 无标度网络，然后模拟 IC 模型的级联传播。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成网络\n",
    "gen = NetworkGenerator(seed=SEED)\n",
    "G = gen.generate_ba(n=300, m=3)\n",
    "\n",
    "print(f\"网络统计:\")\n",
    "print(f\"  节点数: {G.number_of_nodes()}\")\n",
    "print(f\"  边数: {G.number_of_edges()}\")\n",
    "print(f\"  平均度: {np.mean([d for n, d in G.degree()]):.2f}\")\n",
    "\n",
    "# 分配 IC 概率\n",
    "G = gen.assign_ic_probabilities(G, prob_range=(0.01, 0.1))\n",
    "\n",
    "print(\"\\n✓ 网络生成完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 可视化网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建可视化器\n",
    "viz = NetworkVisualizer(G, figsize=(10, 8))\n",
    "\n",
    "# 绘制网络\n",
    "viz.plot_network(title=\"BA 无标度网络\", show_labels=False)\n",
    "\n",
    "# 绘制度分布\n",
    "viz.plot_degree_distribution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成级联数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成级联\n",
    "cascade_gen = CascadeGenerator(G, seed=SEED)\n",
    "cascades = cascade_gen.generate_cascades('ic', num_cascades=500)\n",
    "\n",
    "# 统计\n",
    "cascade_sizes = [c['cascade_size'] for c in cascades]\n",
    "print(f\"级联统计:\")\n",
    "print(f\"  总数: {len(cascades)}\")\n",
    "print(f\"  平均大小: {np.mean(cascade_sizes):.2f}\")\n",
    "print(f\"  最大大小: {max(cascade_sizes)}\")\n",
    "print(f\"  最小大小: {min(cascade_sizes)}\")\n",
    "\n",
    "# 可视化级联大小分布\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(cascade_sizes, bins=30, alpha=0.7, edgecolor='black')\n",
    "plt.xlabel('级联大小', fontsize=12)\n",
    "plt.ylabel('频率', fontsize=12)\n",
    "plt.title('级联大小分布', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ 级联生成完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 训练参数学习模型\n",
    "\n",
    "使用生成的级联数据训练 PyTorch 模型来学习边传播概率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将级联转换为训练数据\n",
    "edges, labels = cascade_gen.cascades_to_training_data(cascades)\n",
    "\n",
    "print(f\"训练数据:\")\n",
    "print(f\"  样本数: {len(edges)}\")\n",
    "print(f\"  正样本比例: {np.mean(labels):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据划分\n",
    "splitter = DataSplitter(seed=SEED)\n",
    "train_edges, train_labels, val_edges, val_labels, test_edges, test_labels = \\\n",
    "    splitter.split_edges(edges, labels)\n",
    "\n",
    "print(f\"数据划分:\")\n",
    "print(f\"  训练集: {len(train_edges)}\")\n",
    "print(f\"  验证集: {len(val_edges)}\")\n",
    "print(f\"  测试集: {len(test_edges)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成嵌入\n",
    "print(\"生成 Node2Vec 嵌入...\")\n",
    "embedding_gen = GraphEmbedding(G, embedding_dim=64, seed=SEED)\n",
    "embeddings = embedding_gen.train_node2vec(num_walks=10, walk_length=40, workers=4)\n",
    "\n",
    "# 准备特征\n",
    "print(\"准备特征...\")\n",
    "train_features = np.array([embedding_gen.get_edge_features(e) for e in train_edges])\n",
    "val_features = np.array([embedding_gen.get_edge_features(e) for e in val_edges])\n",
    "test_features = np.array([embedding_gen.get_edge_features(e) for e in test_edges])\n",
    "train_labels = np.array(train_labels)\n",
    "val_labels = np.array(val_labels)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "print(f\"特征维度: {train_features.shape[1]}\")\n",
    "print(\"\\n✓ 特征准备完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练模型\n",
    "print(\"训练参数学习模型...\")\n",
    "learner = ParameterLearner(\n",
    "    input_dim=train_features.shape[1],\n",
    "    hidden_dims=[128, 64],\n",
    "    dropout=0.3,\n",
    "    learning_rate=0.001,\n",
    "    device='cpu',  # 改为 'cuda' 如果有 GPU\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "history = learner.fit(\n",
    "    train_features, train_labels,\n",
    "    val_features, val_labels,\n",
    "    epochs=50,\n",
    "    batch_size=128,\n",
    "    early_stopping_patience=10,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\n✓ 模型训练完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化训练历史\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 评估测试集\n",
    "test_predictions = learner.predict(test_features)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, classification_report\n",
    "\n",
    "binary_labels = (test_labels > 0).astype(int)\n",
    "binary_preds = (test_predictions > 0.5).astype(int)\n",
    "\n",
    "print(\"测试集性能:\")\n",
    "print(f\"  AUC: {roc_auc_score(binary_labels, test_predictions):.4f}\")\n",
    "print(f\"  准确率: {accuracy_score(binary_labels, binary_preds):.4f}\")\n",
    "print(\"\\n分类报告:\")\n",
    "print(classification_report(binary_labels, binary_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建学习参数的图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为所有边预测概率\n",
    "G_learned = G.copy()\n",
    "all_edges = list(G_learned.edges())\n",
    "edge_features = np.array([embedding_gen.get_edge_features(e) for e in all_edges])\n",
    "learned_probs = learner.predict(edge_features)\n",
    "\n",
    "# 分配学习到的概率\n",
    "for edge, prob in zip(all_edges, learned_probs):\n",
    "    G_learned[edge[0]][edge[1]]['prob'] = float(prob)\n",
    "\n",
    "print(\"✓ 学习参数的图创建完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 运行影响力最大化算法\n",
    "\n",
    "使用真实参数和学习参数分别运行多种影响力最大化算法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参数设置\n",
    "K = 5  # 种子节点数\n",
    "NUM_SIMULATIONS = 500  # MC 模拟次数\n",
    "\n",
    "# 存储结果\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用真实参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"使用真实参数\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "sim_true = DiffusionSimulator(G, model='ic', seed=SEED)\n",
    "\n",
    "# Lazy Greedy\n",
    "print(\"\\n[1] Lazy Greedy...\")\n",
    "greedy = LazyGreedyIM(G, sim_true, seed=SEED)\n",
    "seeds_greedy, gains, time_greedy = greedy.select_seeds(K, NUM_SIMULATIONS, verbose=False)\n",
    "inf_greedy = sim_true.estimate_influence(seeds_greedy, NUM_SIMULATIONS)\n",
    "results['True-LazyGreedy'] = {'seeds': seeds_greedy, 'influence': inf_greedy, 'time': time_greedy}\n",
    "print(f\"  种子: {seeds_greedy}\")\n",
    "print(f\"  影响力: {inf_greedy:.2f}\")\n",
    "print(f\"  时间: {time_greedy:.2f}s\")\n",
    "\n",
    "# TIM\n",
    "print(\"\\n[2] TIM...\")\n",
    "tim = TIM(G, model='ic', seed=SEED)\n",
    "seeds_tim, _, time_tim = tim.select_seeds(K, epsilon=0.5, verbose=False)\n",
    "inf_tim = sim_true.estimate_influence(seeds_tim, NUM_SIMULATIONS)\n",
    "results['True-TIM'] = {'seeds': seeds_tim, 'influence': inf_tim, 'time': time_tim}\n",
    "print(f\"  种子: {seeds_tim}\")\n",
    "print(f\"  影响力: {inf_tim:.2f}\")\n",
    "print(f\"  时间: {time_tim:.2f}s\")\n",
    "\n",
    "# Degree Heuristic\n",
    "print(\"\\n[3] Degree Heuristic...\")\n",
    "degree_h = DegreeHeuristic(G, seed=SEED)\n",
    "seeds_degree, time_degree = degree_h.select_seeds(K)\n",
    "inf_degree = sim_true.estimate_influence(seeds_degree, NUM_SIMULATIONS)\n",
    "results['True-Degree'] = {'seeds': seeds_degree, 'influence': inf_degree, 'time': time_degree}\n",
    "print(f\"  种子: {seeds_degree}\")\n",
    "print(f\"  影响力: {inf_degree:.2f}\")\n",
    "print(f\"  时间: {time_degree:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用学习参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"使用学习参数\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "sim_learned = DiffusionSimulator(G_learned, model='ic', seed=SEED)\n",
    "\n",
    "# Lazy Greedy\n",
    "print(\"\\n[1] Lazy Greedy...\")\n",
    "greedy_l = LazyGreedyIM(G_learned, sim_learned, seed=SEED)\n",
    "seeds_greedy_l, gains_l, time_greedy_l = greedy_l.select_seeds(K, NUM_SIMULATIONS, verbose=False)\n",
    "# 在真实参数下评估\n",
    "inf_greedy_l = sim_true.estimate_influence(seeds_greedy_l, NUM_SIMULATIONS)\n",
    "results['Learned-LazyGreedy'] = {'seeds': seeds_greedy_l, 'influence': inf_greedy_l, 'time': time_greedy_l}\n",
    "print(f\"  种子: {seeds_greedy_l}\")\n",
    "print(f\"  影响力(真实): {inf_greedy_l:.2f}\")\n",
    "print(f\"  时间: {time_greedy_l:.2f}s\")\n",
    "\n",
    "# TIM\n",
    "print(\"\\n[2] TIM...\")\n",
    "tim_l = TIM(G_learned, model='ic', seed=SEED)\n",
    "seeds_tim_l, _, time_tim_l = tim_l.select_seeds(K, epsilon=0.5, verbose=False)\n",
    "inf_tim_l = sim_true.estimate_influence(seeds_tim_l, NUM_SIMULATIONS)\n",
    "results['Learned-TIM'] = {'seeds': seeds_tim_l, 'influence': inf_tim_l, 'time': time_tim_l}\n",
    "print(f\"  种子: {seeds_tim_l}\")\n",
    "print(f\"  影响力(真实): {inf_tim_l:.2f}\")\n",
    "print(f\"  时间: {time_tim_l:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 结果对比分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 影响力对比\n",
    "plot_data = {k: [v['influence']] for k, v in results.items()}\n",
    "plot_influence_comparison(plot_data)\n",
    "\n",
    "# 运行时间对比\n",
    "from src.utils import plot_runtime_comparison\n",
    "runtime_data = {k: v['time'] for k, v in results.items()}\n",
    "plot_runtime_comparison(runtime_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 种子节点重叠分析\n",
    "true_seeds = set(results['True-LazyGreedy']['seeds'])\n",
    "learned_seeds = set(results['Learned-LazyGreedy']['seeds'])\n",
    "\n",
    "overlap = len(true_seeds.intersection(learned_seeds))\n",
    "jaccard = overlap / len(true_seeds.union(learned_seeds))\n",
    "\n",
    "print(f\"种子节点重叠分析 (LazyGreedy):\")\n",
    "print(f\"  真实参数种子: {sorted(true_seeds)}\")\n",
    "print(f\"  学习参数种子: {sorted(learned_seeds)}\")\n",
    "print(f\"  重叠数: {overlap}/{K}\")\n",
    "print(f\"  Jaccard 系数: {jaccard:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 可视化\n",
    "\n",
    "可视化选出的种子节点和传播过程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化选出的种子节点\n",
    "viz_seeds = NetworkVisualizer(G, figsize=(10, 8))\n",
    "viz_seeds.pos = viz.pos  # 使用相同的布局\n",
    "viz_seeds.plot_network(\n",
    "    highlighted_nodes=results['True-LazyGreedy']['seeds'],\n",
    "    title=\"选出的种子节点 (Lazy Greedy - 真实参数)\",\n",
    "    show_labels=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模拟一次传播并可视化\n",
    "seeds = results['True-LazyGreedy']['seeds']\n",
    "activated, edges = sim_true.model.simulate_single(seeds)\n",
    "\n",
    "print(f\"传播结果:\")\n",
    "print(f\"  种子节点: {seeds}\")\n",
    "print(f\"  激活节点数: {len(activated)}\")\n",
    "print(f\"  激活边数: {len(edges)}\")\n",
    "\n",
    "# 创建快照\n",
    "animator = CascadeAnimator(G, pos=viz.pos)\n",
    "animator.create_cascade_snapshots(\n",
    "    cascade_edges=edges,\n",
    "    initial_nodes=seeds,\n",
    "    num_snapshots=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "在本教程中，我们完成了：\n",
    "\n",
    "1. ✅ 生成了一个 BA 无标度网络\n",
    "2. ✅ 模拟了 IC 模型的级联传播\n",
    "3. ✅ 使用 PyTorch 训练了参数学习模型\n",
    "4. ✅ 运行了多种影响力最大化算法\n",
    "5. ✅ 对比了真实参数和学习参数的效果\n",
    "6. ✅ 可视化了网络和传播过程\n",
    "\n",
    "### 关键发现\n",
    "\n",
    "- 参数学习模型达到了较好的 AUC (通常 > 0.8)\n",
    "- 学习参数下选出的种子节点与真实参数有一定重叠\n",
    "- Lazy Greedy 和 TIM 算法在影响力上接近，但 TIM 更快\n",
    "- 启发式方法（Degree）速度快但影响力较低\n",
    "\n",
    "### 扩展练习\n",
    "\n",
    "1. 尝试不同的网络类型（ER, WS）\n",
    "2. 调整参数学习模型的超参数\n",
    "3. 测试 IMM 算法\n",
    "4. 在真实数据集上运行实验\n",
    "5. 使用结构特征增强模型"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
